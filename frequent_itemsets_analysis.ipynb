{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfc5d5b",
   "metadata": {},
   "source": [
    "## *Exploring Frequent Itemsets: Closed vs Maximal in Supermarket Data*\n",
    "### *Introduction: Understanding Maximal and Closed Frequent Itemsets*\n",
    "\n",
    "#### *Frequent Itemsets*\n",
    "\n",
    "*A frequent itemset is a set of items that appears together in a dataset more than a specified minimum number of times, known as the support threshold.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Closed Frequent Itemsets*\n",
    "\n",
    "*A closed frequent itemset is a frequent itemset for which no superset has the same support.*\n",
    "\n",
    "*In other words, it is not possible to add any more items to the set without decreasing how often it appears. Closed itemsets help reduce redundancy while preserving complete support information.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Maximal Frequent Itemsets*\n",
    "\n",
    "*A maximal frequent itemset is a frequent itemset for which no superset is also frequent.*\n",
    "\n",
    "*This means that no additional items can be added to the itemset while still satisfying the minimum support threshold. Maximal itemsets provide a highly compact representation of frequent patterns.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4596a67a",
   "metadata": {},
   "source": [
    "### *[Student: Mohammed]*\n",
    "*Import necessary libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "00e6489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Import pandas for data manipulation\n",
    "import numpy as np # Import numpy for numerical operations\n",
    "\n",
    "import random    # Import random for generating random numbers\n",
    "from mlxtend.frequent_patterns import apriori   # Import apriori algorithm from mlxtend for frequent itemset mining\n",
    "from collections import defaultdict     # Import defaultdict for creating dictionaries with default values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3acc6",
   "metadata": {},
   "source": [
    "## *Step-1:Generating Supermarket Transactions*\n",
    "\n",
    "*This section generates `3,000 supermarket transactions.` Each transaction includes between `2 to 7 items` randomly selected from a pool of `30 unique grocery items.` To ensure reproducibility, a random seed is set. The resulting transactions are stored in a pandas DataFrame and saved as a CSV file for future use.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25885d28",
   "metadata": {},
   "source": [
    " ### *Define Item Pool*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "e20a8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3000 supermarket transactions\n",
    "# Each transaction will have between 2 and 7 items randomly chosen from a pool of 30 unique items\n",
    "\n",
    "#Define the item pool\n",
    "item_pool = [   # List of 30 unique grocery items\n",
    "    'Milk', 'Bread', 'Butter', 'Eggs', 'Cheese', 'Apples', 'Bananas', 'Chicken',\n",
    "    'Beef', 'Fish', 'Rice', 'Pasta', 'Cereal', 'Juice', 'Soda', 'Yogurt',\n",
    "    'Tomatoes', 'Onions', 'Potatoes', 'Carrots', 'Cookies', 'Chips', 'Ice Cream',\n",
    "    'Coffee', 'Tea', 'Sugar', 'Flour', 'Salt', 'Pepper', 'Oil'\n",
    "]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60060de2",
   "metadata": {},
   "source": [
    "###  *Generating Supermarket Transactions*\n",
    "\n",
    "*We generate 3,000 transactions by randomly sampling between 2 and 7 items from the predefined item pool. A random seed is set for reproducibility.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "43e1aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate transactions\n",
    "random.seed(42)  # For reproducibility\n",
    "transactions = []     # List to hold the transactions\n",
    "# Create 3000 transactions\n",
    "for _ in range(3000):\n",
    "    transaction = random.sample(item_pool, k=random.randint(2, 7))  # 2 to 7 items per transaction\n",
    "    transactions.append(transaction)   # Append the transaction to the list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8597dc1",
   "metadata": {},
   "source": [
    "### *Save and Display*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "f39b6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 3000\n",
      "DataFrame shape: (3000, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Transaction",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "52df0823-1262-4e74-9f01-b3d07bca9b50",
       "rows": [
        [
         "0",
         "['Eggs', 'Milk', 'Coffee', 'Beef', 'Chicken', 'Sugar', 'Cheese']"
        ],
        [
         "1",
         "['Eggs', 'Chips', 'Coffee', 'Onions', 'Butter', 'Potatoes', 'Juice']"
        ],
        [
         "2",
         "['Milk', 'Butter']"
        ],
        [
         "3",
         "['Chicken', 'Tomatoes', 'Carrots']"
        ],
        [
         "4",
         "['Onions', 'Bananas']"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Eggs, Milk, Coffee, Beef, Chicken, Sugar, Che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Eggs, Chips, Coffee, Onions, Butter, Potatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Milk, Butter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Chicken, Tomatoes, Carrots]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Onions, Bananas]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Transaction\n",
       "0  [Eggs, Milk, Coffee, Beef, Chicken, Sugar, Che...\n",
       "1  [Eggs, Chips, Coffee, Onions, Butter, Potatoes...\n",
       "2                                     [Milk, Butter]\n",
       "3                       [Chicken, Tomatoes, Carrots]\n",
       "4                                  [Onions, Bananas]"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save the transactions to a CSV file to spefic directory\n",
    "df_transactions = pd.DataFrame({'Transaction': transactions})      # Creating a DataFrame from the transactions list\n",
    "df_transactions.to_csv('data/supermarket_transactions.csv', index=False)   # Saving the DataFrame to a CSV file\n",
    "\n",
    "\n",
    "# Display shape of the DataFrame\n",
    "print(\"Number of transactions:\", df_transactions.shape[0])    # Display the number of transactions\n",
    "print(\"DataFrame shape:\", df_transactions.shape)  # Display the shape of the DataFrame\n",
    "df_transactions.head()   # Display the first few transactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658435ce",
   "metadata": {},
   "source": [
    "## *[Student: Lesala]*\n",
    "\n",
    "## *Step-2:Encoding and Mining Frequent Itemsets*\n",
    "\n",
    "*In this section, we transform the transaction data into a one-hot encoded format and apply the Apriori algorithm to identify the most frequently purchased item combinations. Itemsets that appear in at least 5% of transactions are retained.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298ecaa",
   "metadata": {},
   "source": [
    "#### *One-Hot Encode the Transactions*\n",
    "*We convert each transaction—a list of purchased items—into a format suitable for the Apriori algorithm. Each row represents a transaction, and each column corresponds to an item, marked as `True` if present in that transaction and `False` otherwise. This binary structure is crucial for applying the Apriori method.*\n",
    "\n",
    "---\n",
    "\n",
    "##### *Why this is necessary ?*\n",
    "*The Apriori algorithm requires data in a tabular format where each transaction is a binary vector. Without one-hot encoding, the algorithm wouldn't know which items co-occur across transactions.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "ea939098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of items to one-hot encoded DataFrame\n",
    "\n",
    "# Each row is a transaction, each column is an item, and values are True/False\n",
    "encoded_data = []\n",
    "\n",
    "# Loop through each transaction (a list of items)\n",
    "for transaction in transactions:\n",
    "    # Create a dictionary for each transaction\n",
    "    # Key: item name\n",
    "    # Value: True if item is in the transaction, else False\n",
    "    encoded_row = {item: (item in transaction) for item in item_pool}\n",
    "    \n",
    "    # Add the encoded transaction to the list\n",
    "    encoded_data.append(encoded_row)\n",
    "\n",
    "df = pd.DataFrame(encoded_data)  # Create one-hot encoded DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b5207f",
   "metadata": {},
   "source": [
    "###  *Find Frequent Itemsets using the Apriori Algorithm*\n",
    "\n",
    "*We use the `mlxtend` library’s `apriori` function to identify frequent itemsets—combinations of items that appear together in at least 5% of transactions.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Why this is necessary:*\n",
    "\n",
    "*Identifying frequent itemsets helps uncover common buying patterns. This is foundational for later steps like generating association rules, which tell us how the presence of one item implies another.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "01f3fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Frequent Itemsets using Apriori algorithm\n",
    "# Minimum support threshold is 0.05 (i.e., items appearing in at least 5% of transactions)\n",
    "frequent_itemsets = apriori(df, min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91210b3e",
   "metadata": {},
   "source": [
    "### *Sorting and Exporting the Top Itemsets*\n",
    "\n",
    "*After generating frequent itemsets, we sort them by support (frequency of occurrence) and export the top 10 for reporting and further analysis.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Why this is necessary:*\n",
    "\n",
    "*Sorting allows us to focus on the most significant patterns, while exporting ensures we can reuse or share the findings in a reproducible and organized way.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "20556343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Frequent Itemsets:\n",
      "      support     itemsets\n",
      "21  0.170000      (Chips)\n",
      "3   0.162333       (Eggs)\n",
      "15  0.161000     (Yogurt)\n",
      "20  0.159333    (Cookies)\n",
      "4   0.159000     (Cheese)\n",
      "22  0.156667  (Ice Cream)\n",
      "13  0.154333      (Juice)\n",
      "14  0.154000       (Soda)\n",
      "23  0.154000     (Coffee)\n",
      "9   0.152667       (Fish)\n"
     ]
    }
   ],
   "source": [
    "# Sort the itemsets by support in descending order\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "\n",
    "#Save the top 10 frequent itemsets to CSV\n",
    "frequent_itemsets.head(10).to_csv('data/frequent_itemsets.csv', index=False)\n",
    "#Display output summaries\n",
    "print(\"\\nTop 10 Frequent Itemsets:\\n\", frequent_itemsets.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70441d3e",
   "metadata": {},
   "source": [
    "### *[Student: Halima]*\n",
    "## *Step 3: Identify Closed Frequent Itemsets*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3a85b",
   "metadata": {},
   "source": [
    "### *Introduction: Understanding Maximal and Closed Frequent Itemsets*\n",
    "\n",
    "In *Market Basket Analysis*, one of our goals is to uncover frequent patterns—groups of items that appear together in many transactions.\n",
    "\n",
    "However, as we mine more patterns, the number of frequent itemsets can *grow explosively*. This leads to *redundancy* and makes interpretation more difficult.\n",
    "\n",
    "*To solve this*, we use *condensed representations* of frequent itemsets:\n",
    "\n",
    "* *Maximal Frequent Itemsets (MFI)*\n",
    "* *Closed Frequent Itemsets (CFI)*\n",
    "\n",
    "These approaches help reduce the number of itemsets while retaining the most important information for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3d214",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### *What is Support?*\n",
    "\n",
    "**Support** is a measure that tells you **how often an itemset appears in the dataset**, expressed as a **proportion of total transactions**.\n",
    "\n",
    "---\n",
    "\n",
    "###  *Support Formula*\n",
    "\\[\n",
    "\\text{Support}(X) = \\frac{\\text{Number of transactions containing } X}{\\text{Total number of transactions}}\n",
    "\\]\n",
    "\n",
    "\n",
    "Where:\n",
    "- **Support(X)** is the support of itemset **X**.\n",
    "- **Number of transactions containing X** is how many transactions include the itemset.\n",
    "- **Total number of transactions** is the total count of all transactions in the dataset.\n",
    "- The result is a number between 0 and 1 (or between 0% and 100%).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "ccc6bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Closed Itemsets:\n",
      "\n",
      "     support     itemsets  approx_occurrences\n",
      "21  0.170000      (Chips)                 510\n",
      "3   0.162333       (Eggs)                 487\n",
      "15  0.161000     (Yogurt)                 483\n",
      "20  0.159333    (Cookies)                 478\n",
      "4   0.159000     (Cheese)                 477\n",
      "22  0.156667  (Ice Cream)                 470\n",
      "13  0.154333      (Juice)                 463\n",
      "14  0.154000       (Soda)                 462\n",
      "23  0.154000     (Coffee)                 462\n",
      "9   0.152667       (Fish)                 458\n",
      "\n",
      "Total Number of Closed Itemsets: 30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# An itemset is closed if there is no superset with the same support\n",
    "\n",
    "closed_itemsets = []\n",
    "for i, row_i in frequent_itemsets.iterrows():\n",
    "    is_closed = True\n",
    "    for j, row_j in frequent_itemsets.iterrows():\n",
    "        if row_i['itemsets'] < row_j['itemsets'] and row_i['support'] == row_j['support']:\n",
    "            is_closed = False\n",
    "            break\n",
    "    if is_closed:\n",
    "        closed_itemsets.append(row_i)\n",
    "\n",
    "#Convert closed itemsets list to DataFrame and save to data folder\n",
    "closed_df = pd.DataFrame(closed_itemsets)\n",
    "closed_df.to_csv('data/closed_itemsets.csv', index=False)\n",
    "\n",
    "# Convert closed itemsets list to DataFrame\n",
    "closed_df = pd.DataFrame(closed_itemsets)\n",
    "\n",
    "# Add Approximate Occurrences\n",
    "total_transactions = df.shape[0]  # Total number of transactions in your dataset\n",
    "closed_df['approx_occurrences'] = (closed_df['support'] * total_transactions).round().astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "closed_df.to_csv('data/closed_itemsets.csv', index=False)\n",
    "\n",
    "# Display output summaries\n",
    "print(\"\\nTop 10 Closed Itemsets:\\n\")\n",
    "print(closed_df[['support', 'itemsets', 'approx_occurrences']].head(10))\n",
    "\n",
    "print(\"\\nTotal Number of Closed Itemsets:\", len(closed_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78a9fc",
   "metadata": {},
   "source": [
    "## *Interpretation of Closed Frequent Itemsets*\n",
    "\n",
    "*We analyzed 3,000 simulated supermarket transactions using the Apriori algorithm to discover frequent itemsets, and then filtered the results to find closed frequent itemsets. This method helped eliminate redundant patterns while preserving essential support information.*\n",
    "\n",
    "---\n",
    "\n",
    "### *What Are Closed Itemsets?*\n",
    "\n",
    "*A closed itemset is a frequent itemset for which no superset has the same support. In other words, you can't add more items to the set without lowering how often it appears. Closed itemsets are valuable because they:*\n",
    "\n",
    "*- Represent non-redundant patterns*\n",
    "*- Preserve support values for all items*\n",
    "*- Provide compact but complete summaries of frequent patterns*\n",
    "\n",
    "---\n",
    "\n",
    "### *Summary of Results*\n",
    "\n",
    "*We identified:*\n",
    "\n",
    "*- 30 closed frequent itemsets*\n",
    "*- Top 10 are all single items*\n",
    "*- Support values range between 15% and 17%*\n",
    "\n",
    "*Here are the top 10 closed itemsets:*\n",
    "\n",
    "| *Rank* | *Itemset*     | *Support*  | *Approx. Occurrences* |\n",
    "| ------ | ------------- | ---------- | --------------------- |\n",
    "| *1*    | *(Chips)*     | *0.170000* | *510 transactions*    |\n",
    "| *2*    | *(Eggs)*      | *0.162333* | *487 transactions*    |\n",
    "| *3*    | *(Yogurt)*    | *0.161000* | *483 transactions*    |\n",
    "| *4*    | *(Cookies)*   | *0.159333* | *478 transactions*    |\n",
    "| *5*    | *(Cheese)*    | *0.159000* | *477 transactions*    |\n",
    "| *6*    | *(Ice Cream)* | *0.156667* | *470 transactions*    |\n",
    "| *7*    | *(Juice)*     | *0.154333* | *463 transactions*    |\n",
    "| *8*    | *(Soda)*      | *0.154000* | *462 transactions*    |\n",
    "| *9*    | *(Coffee)*    | *0.154000* | *462 transactions*    |\n",
    "| *10*   | *(Fish)*      | *0.152667* | *458 transactions*    |\n",
    "\n",
    "---\n",
    "\n",
    "### *Interpretation by Key Observations*\n",
    "\n",
    "#### *1. Most Closed Itemsets Are Single Products*\n",
    "\n",
    "*The top closed itemsets are individual items.*\n",
    "*This means these products are frequently purchased alone, not consistently paired with others.*\n",
    "*Their status as closed means that no frequent superset (e.g., Chips + Soda) occurs with the same frequency.*\n",
    "\n",
    "*Insight:*\n",
    "\n",
    "*These are strong independent sellers that customers purchase regularly, without always pairing them.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *2. Consistent Support Values Across Items*\n",
    "\n",
    "*Support values range narrowly from 15% to 17%.*\n",
    "*This suggests a balanced set of popular items, not just one or two dominant ones.*\n",
    "\n",
    "`*Insight:*`\n",
    "\n",
    "*The store benefits from a diversified demand across multiple products, reducing overreliance on a few best-sellers.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *3. No Frequent Pairs or Triplets in Top Results*\n",
    "\n",
    "*All top closed itemsets are length 1, meaning pairs or larger groups did not qualify as closed.*\n",
    "*This implies that customers tend to buy diverse item combinations, and not the same sets repeatedly.*\n",
    "\n",
    "`*Insight:*`\n",
    "\n",
    "*Cross-selling opportunities might not come from frequency alone, and association rules (like lift and confidence) could better capture related buying patterns.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *4. Relatively Small Number of Closed Itemsets*\n",
    "\n",
    "*Only 30 closed itemsets out of thousands of potential combinations.*\n",
    "*This reflects that most combinations are either:*\n",
    "*- Not frequent enough, or*\n",
    "*- Redundant (i.e., have the same support as a subset)*\n",
    "\n",
    "`*Insight:*`\n",
    "\n",
    "*Closed itemsets offer a concise and meaningful summary of frequent patterns — helping analysts focus on what truly matters.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Business Implications*\n",
    "\n",
    "*- Promote top individual products like Chips, Eggs, and Yogurt — they are reliable and popular purchases.*\n",
    "*- Consider targeted bundle offers using association rules to discover less obvious, non-redundant item pairs.*\n",
    "*- Use closed itemsets for efficient inventory planning and to understand core customer preferences.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *Conclusion*\n",
    "\n",
    "*Closed frequent itemsets helped us reduce noise and focus on specific, high-support patterns in customer behavior. While no dominant product combinations were found, several independent best-sellers emerged clearly, offering strong insight for sales and marketing strategies.*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e193905",
   "metadata": {},
   "source": [
    "### *[Student: Snit]*\n",
    "## *Step 4: Identify Maximal Frequent Itemsets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "e240fe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*Top 10 Maximal Frequent Itemsets:*\n",
      "      support     itemsets  occurrences\n",
      "21  0.170000      (Chips)          510\n",
      "3   0.162333       (Eggs)          487\n",
      "15  0.161000     (Yogurt)          483\n",
      "20  0.159333    (Cookies)          478\n",
      "4   0.159000     (Cheese)          477\n",
      "22  0.156667  (Ice Cream)          470\n",
      "13  0.154333      (Juice)          463\n",
      "14  0.154000       (Soda)          462\n",
      "23  0.154000     (Coffee)          462\n",
      "9   0.152667       (Fish)          458\n",
      "\n",
      "*Number of Maximal Frequent Itemsets:* 30\n"
     ]
    }
   ],
   "source": [
    "# Identify Maximal Frequent Itemsets\n",
    "# An itemset is maximal if there is no frequent superset of it\n",
    "\n",
    "maximal_itemsets = []\n",
    "for i, row_i in frequent_itemsets.iterrows():\n",
    "    is_maximal = True\n",
    "    for j, row_j in frequent_itemsets.iterrows():\n",
    "        if row_i['itemsets'] < row_j['itemsets']:\n",
    "            is_maximal = False\n",
    "            break\n",
    "    if is_maximal:\n",
    "        maximal_itemsets.append(row_i)\n",
    "\n",
    "# Convert to DataFrame\n",
    "maximal_df = pd.DataFrame(maximal_itemsets)\n",
    "\n",
    "\n",
    "# Add approximate occurrence count\n",
    "total_transactions = len(df)  # Make sure 'df' is your original transaction DataFrame\n",
    "maximal_df['occurrences'] = (maximal_df['support'] * total_transactions).round().astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "maximal_df.to_csv('data/maximal_itemsets.csv', index=False)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n*Top 10 Maximal Frequent Itemsets:*\\n\", maximal_df.head(10))\n",
    "print(\"\\n*Number of Maximal Frequent Itemsets:*\", len(maximal_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808758c",
   "metadata": {},
   "source": [
    "### *Interpretation of Maximal Frequent Itemsets*\n",
    "\n",
    "*We analyzed 3,000 simulated supermarket transactions using the Apriori algorithm and identified **maximal frequent itemsets** — itemsets for which no frequent superset exists. These represent the **most specific, high-support patterns** that are not further extendable without falling below the support threshold.*\n",
    "\n",
    "---\n",
    "\n",
    "### *What Are Maximal Itemsets?*\n",
    "\n",
    "*A maximal frequent itemset is a frequent itemset that has **no frequent superset**. In simpler terms: you cannot add any more items to the set without its support dropping below the minimum threshold.*\n",
    "\n",
    "*They are valuable because they:*\n",
    "\n",
    "* *Represent the \"boundary\" of frequent patterns*\n",
    "* *Are **more compact** than closed itemsets*\n",
    "* *Omit internal structure (i.e., no support for subsets), focusing only on maximal combinations*\n",
    "\n",
    "---\n",
    "\n",
    "### *Summary of Results*\n",
    "\n",
    "*We identified:*\n",
    "\n",
    "* *30 maximal frequent itemsets*\n",
    "* *Top 10 are all single items — identical to the closed set*\n",
    "* *Support values range from **15.2% to 17%***\n",
    "* *Approximate occurrence counts between **458 and 510** transactions*\n",
    "\n",
    "\n",
    "### *Why Are Maximal and Closed Itemsets Showing the Same Result?*\n",
    "\n",
    "This happens when **none of the larger combinations of items** (pairs, triplets, etc.) meet the support threshold. That is:\n",
    "\n",
    "* The frequent itemsets **larger than size 1** were **not frequent enough** to pass the `min_support` threshold.\n",
    "* Therefore, **no itemset of size > 1** appears in either the closed or maximal result.\n",
    "* In such cases, **closed itemsets ≈ maximal itemsets ≈ frequent itemsets of size 1.**\n",
    "\n",
    ">  *This is a **data-driven limitation**, not an error in logic. You can confirm this by lowering the `min_support` to discover combinations that become frequent.*\n",
    "\n",
    "---\n",
    "\n",
    "### *Interpretation by Key Observations*\n",
    "\n",
    "#### *1. All Maximal Itemsets Are Size 1*\n",
    "\n",
    "*The absence of longer itemsets (pairs, triplets) indicates that item combinations are not commonly repeated across transactions.*\n",
    "\n",
    "*This may be due to:*\n",
    "\n",
    "* *A wide diversity of purchases (many unique combinations)*\n",
    "* *Support threshold set too high for item pairs to qualify*\n",
    "\n",
    "**Insight:** *Customers buy a wide mix of items, so identifying strong bundles may require using association rules like lift and confidence.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *2. High Support, Independent Items*\n",
    "\n",
    "*Items like Chips, Eggs, and Yogurt are reliable best-sellers.*\n",
    "\n",
    "**Insight:** *They are key drivers of traffic and could be used in promotions, featured categories, or stock priority planning.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *3. Maximal Itemsets Are a Compact Summary*\n",
    "\n",
    "*The 30 itemsets cover the essential frequent patterns without including any subsets — this makes them efficient for pattern mining when detail isn't required.*\n",
    "\n",
    "**Insight:** *Maximal itemsets are ideal when you want the most condensed set of patterns that still capture frequent behaviors.*\n",
    "\n",
    "---\n",
    "\n",
    "#### *4. Use Association Rules for Deeper Combinations*\n",
    "\n",
    "*If your goal is to discover bundles or co-purchased items, use `association_rules()` instead of relying only on frequent/maximal itemsets.*\n",
    "\n",
    "\n",
    "### *Business Implications*\n",
    "\n",
    "* *Promote individually strong items seen in top maximal patterns.*\n",
    "* *Explore bundling or cross-selling by analyzing association rules.*\n",
    "* *Use maximal itemsets to simplify downstream reporting or clustering.*\n",
    "\n",
    "---\n",
    "\n",
    "### *Conclusion*\n",
    "\n",
    "*The current data and threshold reveal that single products dominate frequent patterns. While maximal and closed sets appear the same here, the methods remain useful tools — and adjusting parameters like `min_support` may reveal deeper insights.*\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
